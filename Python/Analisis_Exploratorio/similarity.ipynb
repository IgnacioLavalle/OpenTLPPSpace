{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e522400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "data = np.load('../data/SMP22to95_edge_seq.npy', allow_pickle=True)\n",
    "\n",
    "ccodes = pd.read_csv('filtros/ccode_reindexed.csv')\n",
    "pcode_four_digit = pd.read_csv('filtros/pcode_reindexed_four_digit.csv', dtype={'original_code': str})\n",
    "pcode_descriptions = pd.read_csv('filtros/pcode_reindexed.csv', dtype={'original_code': str})\n",
    "pcode_descriptions['original_code'] = pcode_descriptions['original_code'].apply(lambda x: x[:4])\n",
    "aÃ±os = list(range(1995, 1995 + 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "664bf319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_product_and_country_from_edge(u,v):\n",
    "    # teniendo en cuenta que v_adj = v - (max_u + 1) y max_u = 136\n",
    "    original_v =  v + 137\n",
    "    country = ccodes[ccodes['code'] == u]['country_name'].iloc[0]\n",
    "    product_code = pcode_four_digit[pcode_four_digit['code'] == original_v]['original_code'].iloc[0]\n",
    "    product_descriptions = pcode_descriptions[pcode_descriptions['original_code'] == product_code]['description']\n",
    "\n",
    "\n",
    "    print(f\"Pais: {country} \\n\")\n",
    "\n",
    "    print(product_code)\n",
    "    print(product_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74baff67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#matrix values\n",
    "max_u = 136\n",
    "max_v = 1354\n",
    "num_v = max_v - max_u  #real quantity of v nodes\n",
    "\n",
    "adj_matrices = []\n",
    "\n",
    "for year_data in data:\n",
    "\n",
    "    adj_matrix = np.zeros((max_u + 1, num_v))\n",
    "\n",
    "    for u, v, w in year_data:\n",
    "        v_adj = v - (max_u + 1)  #adjust v index\n",
    "        if w >= 1:\n",
    "            weight = 1\n",
    "        else:\n",
    "            weight = 0\n",
    "        adj_matrix[u, v_adj] = weight  #fill with binarized rca\n",
    "\n",
    "    adj_matrices.append(adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7c5cfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#matrix values\n",
    "max_u = 136\n",
    "max_v = 1354\n",
    "num_v = max_v - max_u  #real quantity of v nodes\n",
    "\n",
    "adj_matrices_nb = []\n",
    "\n",
    "for year_data in data:\n",
    "\n",
    "    adj_matrix_nb = np.zeros((max_u + 1, num_v))\n",
    "\n",
    "    for u, v, w in year_data:\n",
    "        v_adj = v - (max_u + 1)  #adjust v index\n",
    "        adj_matrix_nb[u, v_adj] = w  #fill with binarized rca\n",
    "\n",
    "    adj_matrices_nb.append(adj_matrix_nb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe17f869",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_Test = (adj_matrices_nb[21] >= 1).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cfaebbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "adj_Test = (adj_matrices_nb[21] >= 1).astype(int)\n",
    "print(np.array_equal(adj_Test, adj_matrices[21]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7928fe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_rca(product,year):\n",
    "    adj_matrix = adj_matrices[year]\n",
    "    frecuency = 0\n",
    "    for country in range(137):\n",
    "        frecuency += adj_matrix[country,product]\n",
    "    return frecuency/137"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34fb8f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_array_21 = np.zeros((1218))\n",
    "for i in range(1218):\n",
    "        probabilities_array_21[i] = probability_rca(i,21) #es bastante mas eficiente guardarlo en un array ya que reutilizamos los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "939b4cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_intersection_rca(product_i, product_j, year):\n",
    "    adj_matrix = adj_matrices[year]\n",
    "    frecuency = 0\n",
    "    for country in range(137):\n",
    "        frecuency += adj_matrix[country,product_i] * adj_matrix[country,product_j]\n",
    "    return frecuency/137\n",
    "\n",
    "def similarity(product_i, product_j, year, probability_array):\n",
    "    intersection = probability_intersection_rca(product_i,product_j,year) \n",
    "    prob_ij = intersection/ probability_array[product_i] #intersection/probability_rca(product_i,year)\n",
    "    prob_ji = intersection/probability_array[product_j] #intersection/probability_rca(product_j,year)\n",
    "    return min(prob_ij,prob_ji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9979d576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_matrix_for(year,probabilities_array):\n",
    "    similarity_matrix = np.zeros((1218,1218))\n",
    "    for i in range(1218):\n",
    "        for j in range(1218):\n",
    "            if i != j:\n",
    "                similarity_matrix[i,j] = similarity(i,j,year,probabilities_array)\n",
    "            else:\n",
    "                similarity_matrix[i,j] = 1\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3455711c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.24324324 0.29411765 ... 0.29411765 0.2962963  0.18181818]\n",
      " [0.24324324 1.         0.24324324 ... 0.16216216 0.16216216 0.16216216]\n",
      " [0.29411765 0.24324324 1.         ... 0.13333333 0.11111111 0.04545455]\n",
      " ...\n",
      " [0.29411765 0.16216216 0.13333333 ... 1.         0.33333333 0.27272727]\n",
      " [0.2962963  0.16216216 0.11111111 ... 0.33333333 1.         0.40740741]\n",
      " [0.18181818 0.16216216 0.04545455 ... 0.27272727 0.40740741 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "similarity_21 = similarity_matrix_for(21,probabilities_array_21)\n",
    "print(similarity_21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8bc8fb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24324324 1.         0.24324324 ... 0.16216216 0.16216216 0.16216216]\n"
     ]
    }
   ],
   "source": [
    "print(similarity_21[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "633f7f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(1.0), np.float64(0.588235294117647), np.float64(0.5833333333333333), np.float64(0.5833333333333333), np.float64(0.5714285714285714), np.float64(0.5454545454545455), np.float64(0.5454545454545455), np.float64(0.5454545454545455), np.float64(0.5384615384615384), np.float64(0.5384615384615384), np.float64(0.5384615384615384), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.5), np.float64(0.47058823529411764), np.float64(0.47058823529411764), np.float64(0.4666666666666666), np.float64(0.4666666666666666), np.float64(0.4666666666666666), np.float64(0.4666666666666666), np.float64(0.46153846153846156), np.float64(0.46153846153846156), np.float64(0.45454545454545453), np.float64(0.45454545454545453), np.float64(0.45454545454545453), np.float64(0.45454545454545453), np.float64(0.45454545454545453), np.float64(0.45454545454545453), np.float64(0.4375), np.float64(0.4375), np.float64(0.4375), np.float64(0.4285714285714286), np.float64(0.4285714285714286), np.float64(0.4285714285714286), np.float64(0.41666666666666663), np.float64(0.41666666666666663), np.float64(0.41666666666666663), np.float64(0.41666666666666663), np.float64(0.41666666666666663), np.float64(0.41666666666666663), np.float64(0.41666666666666663), np.float64(0.4117647058823529), np.float64(0.4117647058823529), np.float64(0.4), np.float64(0.391304347826087), np.float64(0.3888888888888889), np.float64(0.3846153846153846), np.float64(0.3846153846153846), np.float64(0.3846153846153846), np.float64(0.3846153846153846), np.float64(0.3846153846153846), np.float64(0.3846153846153846), np.float64(0.3846153846153846), np.float64(0.3846153846153846), np.float64(0.37500000000000006), np.float64(0.37500000000000006), np.float64(0.37500000000000006), np.float64(0.37500000000000006), np.float64(0.368421052631579), np.float64(0.368421052631579), np.float64(0.368421052631579), np.float64(0.36363636363636365), np.float64(0.36363636363636365), np.float64(0.36363636363636365), np.float64(0.36363636363636365), np.float64(0.36363636363636365), np.float64(0.36363636363636365), np.float64(0.36363636363636365), np.float64(0.36363636363636365), np.float64(0.36363636363636365), np.float64(0.36363636363636365), np.float64(0.36363636363636365), np.float64(0.36363636363636365), np.float64(0.36363636363636365), np.float64(0.36363636363636365), np.float64(0.36363636363636365), np.float64(0.36363636363636365), np.float64(0.36363636363636365), np.float64(0.36363636363636365), np.float64(0.36363636363636365), np.float64(0.36363636363636365), np.float64(0.36363636363636365), np.float64(0.36363636363636365), np.float64(0.36363636363636365), np.float64(0.36363636363636365), np.float64(0.36363636363636365), np.float64(0.3571428571428571), np.float64(0.3571428571428571), np.float64(0.3571428571428571), np.float64(0.3571428571428571), np.float64(0.3571428571428571), np.float64(0.3571428571428571), np.float64(0.3571428571428571), np.float64(0.3571428571428571), np.float64(0.3571428571428571), np.float64(0.3571428571428571), np.float64(0.3571428571428571), np.float64(0.3571428571428571), np.float64(0.35294117647058826), np.float64(0.35294117647058826), np.float64(0.35294117647058826), np.float64(0.35294117647058826), np.float64(0.35294117647058826), np.float64(0.35294117647058826), np.float64(0.35000000000000003), np.float64(0.35000000000000003), np.float64(0.34782608695652173), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.3333333333333333), np.float64(0.32), np.float64(0.32), np.float64(0.32), np.float64(0.3181818181818182), np.float64(0.3181818181818182), np.float64(0.3181818181818182), np.float64(0.31578947368421056), np.float64(0.31578947368421056), np.float64(0.31578947368421056), np.float64(0.31578947368421056), np.float64(0.3125), np.float64(0.3125), np.float64(0.3125), np.float64(0.3125), np.float64(0.3125), np.float64(0.3125), np.float64(0.3125), np.float64(0.3125), np.float64(0.3125), np.float64(0.3076923076923077), np.float64(0.3076923076923077), np.float64(0.3076923076923077), np.float64(0.3076923076923077), np.float64(0.3076923076923077), np.float64(0.3076923076923077), np.float64(0.3076923076923077), np.float64(0.3076923076923077), np.float64(0.3076923076923077), np.float64(0.3076923076923077), np.float64(0.30434782608695654), np.float64(0.30434782608695654), np.float64(0.30434782608695654), np.float64(0.30000000000000004), np.float64(0.30000000000000004), np.float64(0.30000000000000004), np.float64(0.30000000000000004), np.float64(0.30000000000000004), np.float64(0.2941176470588235), np.float64(0.2941176470588235), np.float64(0.2941176470588235), np.float64(0.2941176470588235), np.float64(0.2941176470588235), np.float64(0.2941176470588235), np.float64(0.2941176470588235), np.float64(0.2941176470588235), np.float64(0.29166666666666663), np.float64(0.29166666666666663), np.float64(0.29166666666666663), np.float64(0.29166666666666663), np.float64(0.29166666666666663), np.float64(0.29166666666666663), np.float64(0.29166666666666663), np.float64(0.29166666666666663), np.float64(0.29166666666666663), np.float64(0.2857142857142857), np.float64(0.2857142857142857), np.float64(0.2857142857142857), np.float64(0.2857142857142857), np.float64(0.2857142857142857), np.float64(0.2857142857142857), np.float64(0.2857142857142857), np.float64(0.2857142857142857), np.float64(0.2857142857142857), np.float64(0.2857142857142857), np.float64(0.2857142857142857), np.float64(0.2857142857142857), np.float64(0.2857142857142857), np.float64(0.2857142857142857), np.float64(0.2857142857142857), np.float64(0.2857142857142857), np.float64(0.2857142857142857), np.float64(0.2857142857142857), np.float64(0.2857142857142857), np.float64(0.2857142857142857), np.float64(0.2857142857142857), np.float64(0.28), np.float64(0.28), np.float64(0.28), np.float64(0.28), np.float64(0.27777777777777773), np.float64(0.27777777777777773), np.float64(0.27777777777777773), np.float64(0.27777777777777773), np.float64(0.27777777777777773), np.float64(0.27777777777777773), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.27272727272727276), np.float64(0.26666666666666666), np.float64(0.26666666666666666), np.float64(0.26666666666666666), np.float64(0.26666666666666666), np.float64(0.26666666666666666), np.float64(0.26666666666666666), np.float64(0.26666666666666666), np.float64(0.26666666666666666), np.float64(0.26666666666666666), np.float64(0.26666666666666666), np.float64(0.26666666666666666), np.float64(0.26666666666666666), np.float64(0.26666666666666666), np.float64(0.26666666666666666), np.float64(0.2631578947368421), np.float64(0.2631578947368421), np.float64(0.2631578947368421), np.float64(0.2631578947368421), np.float64(0.2631578947368421), np.float64(0.2631578947368421), np.float64(0.2631578947368421), np.float64(0.26086956521739135), np.float64(0.25806451612903225), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.25), np.float64(0.2413793103448276), np.float64(0.2413793103448276), np.float64(0.24000000000000002), np.float64(0.24000000000000002), np.float64(0.23809523809523805), np.float64(0.23809523809523805), np.float64(0.23809523809523805), np.float64(0.23809523809523805), np.float64(0.23809523809523805), np.float64(0.23809523809523805), np.float64(0.23809523809523805), np.float64(0.23809523809523805), np.float64(0.23809523809523805), np.float64(0.23529411764705882), np.float64(0.23529411764705882), np.float64(0.23529411764705882), np.float64(0.23529411764705882), np.float64(0.23529411764705882), np.float64(0.23529411764705882), np.float64(0.23529411764705882), np.float64(0.23529411764705882), np.float64(0.23529411764705882), np.float64(0.23529411764705882), np.float64(0.23529411764705882), np.float64(0.23529411764705882), np.float64(0.23529411764705882), np.float64(0.2333333333333333), np.float64(0.23076923076923078), np.float64(0.23076923076923078), np.float64(0.23076923076923078), np.float64(0.23076923076923078), np.float64(0.23076923076923078), np.float64(0.23076923076923078), np.float64(0.23076923076923078), np.float64(0.23076923076923078), np.float64(0.23076923076923078), np.float64(0.23076923076923078), np.float64(0.23076923076923078), np.float64(0.23076923076923078), np.float64(0.23076923076923078), np.float64(0.23076923076923078), np.float64(0.23076923076923078), np.float64(0.23076923076923078), np.float64(0.23076923076923078), np.float64(0.23076923076923078), np.float64(0.23076923076923078), np.float64(0.23076923076923078), np.float64(0.23076923076923078), np.float64(0.23076923076923078), np.float64(0.23076923076923078), np.float64(0.22857142857142854), np.float64(0.22727272727272727), np.float64(0.22727272727272727), np.float64(0.22727272727272727), np.float64(0.22580645161290322), np.float64(0.2222222222222222), np.float64(0.2222222222222222), np.float64(0.2222222222222222), np.float64(0.2222222222222222), np.float64(0.2222222222222222), np.float64(0.2222222222222222), np.float64(0.2222222222222222), np.float64(0.2222222222222222), np.float64(0.2222222222222222), np.float64(0.2222222222222222), np.float64(0.21875), np.float64(0.21739130434782608), np.float64(0.21739130434782608), np.float64(0.21739130434782608), np.float64(0.21739130434782608), np.float64(0.21739130434782608), np.float64(0.2142857142857143), np.float64(0.2142857142857143), np.float64(0.2142857142857143), np.float64(0.2142857142857143), np.float64(0.2142857142857143), np.float64(0.2142857142857143), np.float64(0.2142857142857143), np.float64(0.2142857142857143), np.float64(0.2142857142857143), np.float64(0.2142857142857143), np.float64(0.2142857142857143), np.float64(0.2142857142857143), np.float64(0.2142857142857143), np.float64(0.2142857142857143), np.float64(0.2142857142857143), np.float64(0.2121212121212121), np.float64(0.21052631578947367), np.float64(0.21052631578947367), np.float64(0.21052631578947367), np.float64(0.21052631578947367), np.float64(0.21052631578947367), np.float64(0.20833333333333331), np.float64(0.20833333333333331), np.float64(0.20689655172413796), np.float64(0.20689655172413796), np.float64(0.2), np.float64(0.2), np.float64(0.2), np.float64(0.2), np.float64(0.2), np.float64(0.2), np.float64(0.2), np.float64(0.2), np.float64(0.2), np.float64(0.2), np.float64(0.2), np.float64(0.2), np.float64(0.2), np.float64(0.2), np.float64(0.2), np.float64(0.2), np.float64(0.2), np.float64(0.2), np.float64(0.2), np.float64(0.2), np.float64(0.2), np.float64(0.2), np.float64(0.2), np.float64(0.2), np.float64(0.2), np.float64(0.2), np.float64(0.2), np.float64(0.2), np.float64(0.2), np.float64(0.2), np.float64(0.2), np.float64(0.19999999999999998), np.float64(0.19999999999999998), np.float64(0.19999999999999998), np.float64(0.19999999999999998), np.float64(0.19999999999999998), np.float64(0.19999999999999998), np.float64(0.19999999999999998), np.float64(0.19444444444444445), np.float64(0.19444444444444445), np.float64(0.1935483870967742), np.float64(0.1923076923076923), np.float64(0.1923076923076923), np.float64(0.19047619047619047), np.float64(0.19047619047619047), np.float64(0.19047619047619047), np.float64(0.19047619047619047), np.float64(0.19047619047619047), np.float64(0.19047619047619047), np.float64(0.18750000000000003), np.float64(0.18750000000000003), np.float64(0.18750000000000003), np.float64(0.18750000000000003), np.float64(0.18750000000000003), np.float64(0.18750000000000003), np.float64(0.18750000000000003), np.float64(0.18750000000000003), np.float64(0.18750000000000003), np.float64(0.18750000000000003), np.float64(0.18750000000000003), np.float64(0.18518518518518517), np.float64(0.18518518518518517), np.float64(0.18518518518518517), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.18181818181818182), np.float64(0.1794871794871795), np.float64(0.17857142857142855), np.float64(0.17857142857142855), np.float64(0.17857142857142855), np.float64(0.17647058823529413), np.float64(0.17647058823529413), np.float64(0.17647058823529413), np.float64(0.17647058823529413), np.float64(0.17647058823529413), np.float64(0.17647058823529413), np.float64(0.17647058823529413), np.float64(0.17647058823529413), np.float64(0.17647058823529413), np.float64(0.17647058823529413), np.float64(0.17647058823529413), np.float64(0.17647058823529413), np.float64(0.17647058823529413), np.float64(0.17647058823529413), np.float64(0.17647058823529413), np.float64(0.17391304347826086), np.float64(0.17391304347826086), np.float64(0.17391304347826086), np.float64(0.17391304347826086), np.float64(0.17391304347826086), np.float64(0.17391304347826086), np.float64(0.17391304347826086), np.float64(0.17241379310344826), np.float64(0.17142857142857143), np.float64(0.17142857142857143), np.float64(0.17142857142857143), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.16666666666666666), np.float64(0.1627906976744186), np.float64(0.16129032258064516), np.float64(0.16129032258064516), np.float64(0.16), np.float64(0.16), np.float64(0.16), np.float64(0.16), np.float64(0.16), np.float64(0.16), np.float64(0.16), np.float64(0.15789473684210528), np.float64(0.15789473684210528), np.float64(0.15789473684210528), np.float64(0.15789473684210528), np.float64(0.15789473684210528), np.float64(0.15789473684210528), np.float64(0.15789473684210528), np.float64(0.15789473684210528), np.float64(0.15789473684210528), np.float64(0.15789473684210528), np.float64(0.15789473684210528), np.float64(0.15789473684210528), np.float64(0.15625), np.float64(0.15384615384615385), np.float64(0.15384615384615385), np.float64(0.15384615384615385), np.float64(0.15384615384615385), np.float64(0.15384615384615385), np.float64(0.15384615384615385), np.float64(0.15384615384615385), np.float64(0.15384615384615385), np.float64(0.15384615384615385), np.float64(0.15384615384615385), np.float64(0.1515151515151515), np.float64(0.15000000000000002), np.float64(0.15000000000000002), np.float64(0.15000000000000002), np.float64(0.15000000000000002), np.float64(0.15000000000000002), np.float64(0.15000000000000002), np.float64(0.15000000000000002), np.float64(0.15000000000000002), np.float64(0.15000000000000002), np.float64(0.15000000000000002), np.float64(0.14814814814814814), np.float64(0.14814814814814814), np.float64(0.14814814814814814), np.float64(0.14814814814814814), np.float64(0.14814814814814814), np.float64(0.14814814814814814), np.float64(0.14705882352941174), np.float64(0.14705882352941174), np.float64(0.14634146341463414), np.float64(0.14285714285714285), np.float64(0.14285714285714285), np.float64(0.14285714285714285), np.float64(0.14285714285714285), np.float64(0.14285714285714285), np.float64(0.14285714285714285), np.float64(0.14285714285714285), np.float64(0.14285714285714285), np.float64(0.14285714285714285), np.float64(0.14285714285714285), np.float64(0.14285714285714285), np.float64(0.14285714285714285), np.float64(0.14285714285714285), np.float64(0.14285714285714285), np.float64(0.14285714285714285), np.float64(0.14285714285714285), np.float64(0.14285714285714285), np.float64(0.14285714285714285), np.float64(0.14285714285714285), np.float64(0.14285714285714285), np.float64(0.14285714285714285), np.float64(0.14285714285714285), np.float64(0.14285714285714282), np.float64(0.13953488372093023), np.float64(0.13888888888888887), np.float64(0.13793103448275862), np.float64(0.13793103448275862), np.float64(0.13793103448275862), np.float64(0.13636363636363638), np.float64(0.13636363636363638), np.float64(0.13636363636363638), np.float64(0.13636363636363638), np.float64(0.13636363636363638), np.float64(0.13636363636363638), np.float64(0.13636363636363638), np.float64(0.13636363636363638), np.float64(0.13636363636363638), np.float64(0.13513513513513511), np.float64(0.13333333333333333), np.float64(0.13333333333333333), np.float64(0.13333333333333333), np.float64(0.13333333333333333), np.float64(0.13333333333333333), np.float64(0.13333333333333333), np.float64(0.13333333333333333), np.float64(0.13333333333333333), np.float64(0.13333333333333333), np.float64(0.13333333333333333), np.float64(0.13333333333333333), np.float64(0.13333333333333333), np.float64(0.13333333333333333), np.float64(0.13333333333333333), np.float64(0.13157894736842105), np.float64(0.13157894736842105), np.float64(0.13157894736842105), np.float64(0.13043478260869568), np.float64(0.13043478260869568), np.float64(0.12903225806451613), np.float64(0.12903225806451613), np.float64(0.125), np.float64(0.125), np.float64(0.125), np.float64(0.125), np.float64(0.125), np.float64(0.125), np.float64(0.125), np.float64(0.125), np.float64(0.125), np.float64(0.125), np.float64(0.125), np.float64(0.125), np.float64(0.125), np.float64(0.125), np.float64(0.125), np.float64(0.125), np.float64(0.125), np.float64(0.125), np.float64(0.125), np.float64(0.125), np.float64(0.125), np.float64(0.125), np.float64(0.1212121212121212), np.float64(0.1212121212121212), np.float64(0.12000000000000001), np.float64(0.12000000000000001), np.float64(0.12000000000000001), np.float64(0.12000000000000001), np.float64(0.12000000000000001), np.float64(0.12000000000000001), np.float64(0.11904761904761903), np.float64(0.11764705882352941), np.float64(0.11764705882352941), np.float64(0.11764705882352941), np.float64(0.11764705882352941), np.float64(0.11764705882352941), np.float64(0.11764705882352941), np.float64(0.11764705882352941), np.float64(0.11764705882352941), np.float64(0.11764705882352941), np.float64(0.11764705882352941), np.float64(0.11764705882352941), np.float64(0.11764705882352941), np.float64(0.11764705882352941), np.float64(0.11764705882352941), np.float64(0.11764705882352941), np.float64(0.11764705882352941), np.float64(0.11764705882352941), np.float64(0.11764705882352941), np.float64(0.11627906976744184), np.float64(0.11538461538461539), np.float64(0.11538461538461539), np.float64(0.11538461538461539), np.float64(0.11363636363636363), np.float64(0.1111111111111111), np.float64(0.1111111111111111), np.float64(0.1111111111111111), np.float64(0.1111111111111111), np.float64(0.1111111111111111), np.float64(0.1111111111111111), np.float64(0.1111111111111111), np.float64(0.1111111111111111), np.float64(0.1111111111111111), np.float64(0.1111111111111111), np.float64(0.1081081081081081), np.float64(0.10714285714285715), np.float64(0.10714285714285715), np.float64(0.10714285714285715), np.float64(0.10526315789473684), np.float64(0.10526315789473684), np.float64(0.10526315789473684), np.float64(0.10526315789473684), np.float64(0.10526315789473684), np.float64(0.10526315789473684), np.float64(0.10344827586206898), np.float64(0.10344827586206898), np.float64(0.10344827586206898), np.float64(0.10256410256410256), np.float64(0.1), np.float64(0.1), np.float64(0.1), np.float64(0.1), np.float64(0.1), np.float64(0.1), np.float64(0.1), np.float64(0.1), np.float64(0.1), np.float64(0.1), np.float64(0.0967741935483871), np.float64(0.0967741935483871), np.float64(0.09523809523809523), np.float64(0.09523809523809523), np.float64(0.09523809523809523), np.float64(0.09523809523809523), np.float64(0.09523809523809523), np.float64(0.09523809523809523), np.float64(0.09523809523809523), np.float64(0.09523809523809523), np.float64(0.09523809523809523), np.float64(0.09523809523809523), np.float64(0.09523809523809523), np.float64(0.09375000000000001), np.float64(0.09375000000000001), np.float64(0.09375000000000001), np.float64(0.09375000000000001), np.float64(0.09375000000000001), np.float64(0.09302325581395349), np.float64(0.09302325581395349), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.09090909090909091), np.float64(0.08888888888888889), np.float64(0.08888888888888889), np.float64(0.08823529411764706), np.float64(0.08823529411764706), np.float64(0.08823529411764706), np.float64(0.08823529411764706), np.float64(0.08695652173913043), np.float64(0.08695652173913043), np.float64(0.08571428571428572), np.float64(0.08571428571428572), np.float64(0.08571428571428572), np.float64(0.08571428571428572), np.float64(0.08571428571428572), np.float64(0.08510638297872339), np.float64(0.08333333333333333), np.float64(0.08333333333333333), np.float64(0.08333333333333333), np.float64(0.08333333333333333), np.float64(0.08333333333333333), np.float64(0.08333333333333333), np.float64(0.08333333333333333), np.float64(0.08333333333333333), np.float64(0.08333333333333333), np.float64(0.08333333333333333), np.float64(0.08333333333333333), np.float64(0.08333333333333333), np.float64(0.08333333333333333), np.float64(0.08333333333333333), np.float64(0.08333333333333333), np.float64(0.08163265306122448), np.float64(0.08108108108108109), np.float64(0.08108108108108109), np.float64(0.08), np.float64(0.08), np.float64(0.08), np.float64(0.08), np.float64(0.08), np.float64(0.07894736842105264), np.float64(0.07894736842105264), np.float64(0.07692307692307693), np.float64(0.07692307692307693), np.float64(0.07692307692307693), np.float64(0.07692307692307693), np.float64(0.07692307692307693), np.float64(0.07692307692307693), np.float64(0.07692307692307693), np.float64(0.07692307692307693), np.float64(0.07692307692307693), np.float64(0.07692307692307693), np.float64(0.07692307692307693), np.float64(0.07692307692307693), np.float64(0.07692307692307693), np.float64(0.07692307692307693), np.float64(0.07692307692307693), np.float64(0.07692307692307693), np.float64(0.07692307692307693), np.float64(0.07692307692307693), np.float64(0.07692307692307693), np.float64(0.07692307692307693), np.float64(0.07575757575757575), np.float64(0.07500000000000001), np.float64(0.07500000000000001), np.float64(0.07500000000000001), np.float64(0.07407407407407407), np.float64(0.07407407407407407), np.float64(0.07407407407407407), np.float64(0.07407407407407407), np.float64(0.07142857142857142), np.float64(0.07142857142857142), np.float64(0.07142857142857142), np.float64(0.07142857142857142), np.float64(0.07142857142857142), np.float64(0.07142857142857142), np.float64(0.07142857142857142), np.float64(0.07142857142857142), np.float64(0.07142857142857142), np.float64(0.07142857142857142), np.float64(0.07142857142857142), np.float64(0.07142857142857142), np.float64(0.07142857142857142), np.float64(0.07142857142857142), np.float64(0.07142857142857142), np.float64(0.06976744186046512), np.float64(0.06896551724137931), np.float64(0.06896551724137931), np.float64(0.06896551724137931), np.float64(0.06818181818181819), np.float64(0.06818181818181819), np.float64(0.06666666666666667), np.float64(0.06666666666666667), np.float64(0.06666666666666667), np.float64(0.06666666666666667), np.float64(0.06666666666666667), np.float64(0.06666666666666667), np.float64(0.06666666666666667), np.float64(0.06666666666666667), np.float64(0.06451612903225806), np.float64(0.06451612903225806), np.float64(0.06451612903225806), np.float64(0.06349206349206349), np.float64(0.0625), np.float64(0.0625), np.float64(0.0625), np.float64(0.0625), np.float64(0.0625), np.float64(0.0625), np.float64(0.0625), np.float64(0.0625), np.float64(0.0606060606060606), np.float64(0.0606060606060606), np.float64(0.0606060606060606), np.float64(0.0606060606060606), np.float64(0.058823529411764705), np.float64(0.058823529411764705), np.float64(0.058823529411764705), np.float64(0.058823529411764705), np.float64(0.058823529411764705), np.float64(0.058823529411764705), np.float64(0.058823529411764705), np.float64(0.058823529411764705), np.float64(0.057142857142857134), np.float64(0.057142857142857134), np.float64(0.057142857142857134), np.float64(0.05555555555555555), np.float64(0.05555555555555555), np.float64(0.05555555555555555), np.float64(0.05555555555555555), np.float64(0.05555555555555555), np.float64(0.05555555555555555), np.float64(0.05454545454545455), np.float64(0.05263157894736842), np.float64(0.05263157894736842), np.float64(0.05263157894736842), np.float64(0.05263157894736842), np.float64(0.05263157894736842), np.float64(0.05263157894736842), np.float64(0.05263157894736842), np.float64(0.05263157894736842), np.float64(0.05128205128205128), np.float64(0.05), np.float64(0.05), np.float64(0.05), np.float64(0.05), np.float64(0.05), np.float64(0.05), np.float64(0.05), np.float64(0.05), np.float64(0.048780487804878044), np.float64(0.047619047619047616), np.float64(0.047619047619047616), np.float64(0.047619047619047616), np.float64(0.047619047619047616), np.float64(0.047619047619047616), np.float64(0.047619047619047616), np.float64(0.047619047619047616), np.float64(0.045454545454545456), np.float64(0.045454545454545456), np.float64(0.045454545454545456), np.float64(0.045454545454545456), np.float64(0.044444444444444446), np.float64(0.043478260869565216), np.float64(0.043478260869565216), np.float64(0.043478260869565216), np.float64(0.043478260869565216), np.float64(0.041666666666666664), np.float64(0.041666666666666664), np.float64(0.041666666666666664), np.float64(0.04), np.float64(0.03773584905660377), np.float64(0.037037037037037035), np.float64(0.03571428571428571), np.float64(0.03571428571428571), np.float64(0.03571428571428571), np.float64(0.034482758620689655), np.float64(0.034482758620689655), np.float64(0.03333333333333333), np.float64(0.03225806451612903), np.float64(0.03225806451612903), np.float64(0.03125), np.float64(0.0303030303030303), np.float64(0.0303030303030303), np.float64(0.0303030303030303), np.float64(0.029411764705882353), np.float64(0.029411764705882353), np.float64(0.029411764705882353), np.float64(0.028571428571428567), np.float64(0.028571428571428567), np.float64(0.028571428571428567), np.float64(0.022222222222222223), np.float64(0.021276595744680847), np.float64(0.017543859649122806), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(similarity_21[1009], reverse = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dcb723de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def density_of(country, product, similarity_matrix, adj_matrix):\n",
    "    filtrado = 0\n",
    "    total = 0\n",
    "    for i in range(1218):\n",
    "         similarity = similarity_matrix[i,product] \n",
    "         total += similarity\n",
    "         filtrado += similarity*adj_matrix[country,i]\n",
    "    return filtrado/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "643a345d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.031931206865792476\n"
     ]
    }
   ],
   "source": [
    "print(density_of(3,0,similarity_21, adj_matrices[21]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3fd680c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05453232 0.06594501 0.0341194  ... 0.03469476 0.06012347 0.07426199]\n",
      " [0.01196143 0.01927515 0.01177302 ... 0.01006176 0.01404086 0.01491664]\n",
      " [0.01136614 0.01628891 0.01013246 ... 0.01169198 0.01565672 0.01068169]\n",
      " ...\n",
      " [0.0236212  0.02606517 0.02180776 ... 0.01389703 0.02206116 0.01872524]\n",
      " [0.04056082 0.06204133 0.02878679 ... 0.02872468 0.05061988 0.03959768]\n",
      " [0.05301799 0.08363537 0.05283578 ... 0.04160782 0.06433781 0.06144141]]\n"
     ]
    }
   ],
   "source": [
    "density_matrix = np.zeros((max_u + 1, num_v))\n",
    "\n",
    "for i in range(137):\n",
    "    for j in range(1218):\n",
    "        density_matrix[i,j] = density_of(i,j,similarity_21,adj_matrices[21])\n",
    "\n",
    "print(density_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ddb0db07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(0.5842965658862929), np.float64(0.5821437307466575), np.float64(0.5717302233909208), np.float64(0.5667344597222673), np.float64(0.5618530570312542), np.float64(0.5611764289530916), np.float64(0.5606429260441421), np.float64(0.5570216823983999), np.float64(0.5548457874311413), np.float64(0.5540216245489454), np.float64(0.5529537881016601), np.float64(0.5471202074177327), np.float64(0.5467757745444319), np.float64(0.546032069030703), np.float64(0.5440484110837859), np.float64(0.5431369810278153), np.float64(0.5422726316583528), np.float64(0.5415997190698387), np.float64(0.5386727237231479), np.float64(0.5368883848230557), np.float64(0.5368153163303362), np.float64(0.5356500774612442), np.float64(0.5345239419346355), np.float64(0.5336029356711844), np.float64(0.5303136181627844), np.float64(0.5297724171629984), np.float64(0.5286967306052007), np.float64(0.5253449736134533), np.float64(0.5252367710981769), np.float64(0.524627789552958), np.float64(0.5243051853306906), np.float64(0.5219496165177436), np.float64(0.5211113892908037), np.float64(0.5203471689243027), np.float64(0.518825305486755), np.float64(0.518498552725212), np.float64(0.5181816099314703), np.float64(0.5179731321249819), np.float64(0.5162981864667693), np.float64(0.5142603534038738), np.float64(0.5129475323785726), np.float64(0.5127398539816644), np.float64(0.5124172152258117), np.float64(0.5115815632371511), np.float64(0.5099791493450312), np.float64(0.5098874510314796), np.float64(0.5098125117053096), np.float64(0.5095494447545803), np.float64(0.5093334654761599), np.float64(0.5092576449893254), np.float64(0.508667343695377), np.float64(0.5068854982627462), np.float64(0.5063928654366965), np.float64(0.5043135879672836), np.float64(0.504267133714608), np.float64(0.5032178342352012), np.float64(0.50320659964355), np.float64(0.5030569522203885), np.float64(0.5027317532844032), np.float64(0.5015722663728065), np.float64(0.5008193341179685), np.float64(0.49914017182506953), np.float64(0.49868019785748496), np.float64(0.4976451828033789), np.float64(0.4969446549997386), np.float64(0.4966004669816404), np.float64(0.4953459514904968), np.float64(0.4948361858334057), np.float64(0.49308554078389144), np.float64(0.4925782126716126), np.float64(0.49185928543763346), np.float64(0.4917812429780645), np.float64(0.49144566892044744), np.float64(0.4907045505127393), np.float64(0.489678153424378), np.float64(0.48945000066869987), np.float64(0.4884323738988587), np.float64(0.48842514847057183), np.float64(0.4884227542822837), np.float64(0.4882533542317555), np.float64(0.4874538909143821), np.float64(0.48690539049552817), np.float64(0.48654272394038617), np.float64(0.4857233616264841), np.float64(0.4846502545139994), np.float64(0.4841594047170182), np.float64(0.4839008277400267), np.float64(0.48347480136325954), np.float64(0.4833045711783816), np.float64(0.48306321148483694), np.float64(0.4830114970039837), np.float64(0.48260119609122204), np.float64(0.4820414848255042), np.float64(0.4819670945200314), np.float64(0.48194876923395424), np.float64(0.48127191525509305), np.float64(0.48093844678929654), np.float64(0.48083813939752), np.float64(0.4806397014116586), np.float64(0.48038840167805935), np.float64(0.47987162117057214), np.float64(0.4798676403766881), np.float64(0.4796717408054551), np.float64(0.47930279022816175), np.float64(0.47871443454792817), np.float64(0.47851999427448094), np.float64(0.4784053213194258), np.float64(0.47824265880945327), np.float64(0.4775794321947068), np.float64(0.4775199067057569), np.float64(0.4770011993252509), np.float64(0.4769350607829142), np.float64(0.4769129598717573), np.float64(0.47675235910025493), np.float64(0.47659071732968844), np.float64(0.4759007015097557), np.float64(0.4752553662101862), np.float64(0.4751933277838947), np.float64(0.4748822843105076), np.float64(0.47471484532397273), np.float64(0.4747055853864179), np.float64(0.47439840632484476), np.float64(0.47372006537094946), np.float64(0.47351919856873614), np.float64(0.4734734163500448), np.float64(0.47342005580884866), np.float64(0.4730024807554637), np.float64(0.4726790752259015), np.float64(0.472143044340896), np.float64(0.4714767288824765), np.float64(0.4713855937248908), np.float64(0.4709513622597435), np.float64(0.47090200685350275), np.float64(0.4707426006429344), np.float64(0.470701950261725), np.float64(0.4706153110220007), np.float64(0.4701670559257233), np.float64(0.46976711691690365), np.float64(0.46872064015891607), np.float64(0.46847148699646574), np.float64(0.4674020471040328), np.float64(0.46726064929087946), np.float64(0.46718144887133345), np.float64(0.46691379008895395), np.float64(0.4667521631062602), np.float64(0.4661514251259953), np.float64(0.46579245096858), np.float64(0.4657116430498523), np.float64(0.46553630010143116), np.float64(0.4649597541944795), np.float64(0.46493180973963294), np.float64(0.46412738758631267), np.float64(0.46309642128766926), np.float64(0.4629760749966504), np.float64(0.46257943141763014), np.float64(0.4623201905174815), np.float64(0.4620311353969536), np.float64(0.4613171965201326), np.float64(0.46065902005397674), np.float64(0.4606167228083058), np.float64(0.4605460633931067), np.float64(0.4601796494137055), np.float64(0.46016121315952735), np.float64(0.459172346273819), np.float64(0.4587030677134491), np.float64(0.4583731072652987), np.float64(0.4583689266001441), np.float64(0.45802240427146707), np.float64(0.4577474057426049), np.float64(0.45704045169058055), np.float64(0.4569666099873021), np.float64(0.4568599404038943), np.float64(0.45681702090434967), np.float64(0.4567601510003418), np.float64(0.4562663147941178), np.float64(0.4557749657593545), np.float64(0.4551728915002281), np.float64(0.4549827033792738), np.float64(0.45440188190066244), np.float64(0.45425005088428433), np.float64(0.454136561382992), np.float64(0.45385018250259274), np.float64(0.4536188126066938), np.float64(0.45341646629565013), np.float64(0.4533792313114223), np.float64(0.4532392524726574), np.float64(0.45290664109298545), np.float64(0.4525376409579839), np.float64(0.4524790436202076), np.float64(0.4522351881850759), np.float64(0.45156776087989203), np.float64(0.45129717895723914), np.float64(0.45094147536261825), np.float64(0.4507074228691727), np.float64(0.4502870455456926), np.float64(0.4502167743700102), np.float64(0.4499205541211217), np.float64(0.4499179402871051), np.float64(0.44955909947616746), np.float64(0.4492593009427307), np.float64(0.44914039434733727), np.float64(0.4485465409518192), np.float64(0.44820630477259515), np.float64(0.4481866237570263), np.float64(0.4480217976666354), np.float64(0.4480165463089626), np.float64(0.44770712261565465), np.float64(0.4474551434137628), np.float64(0.44734955127302), np.float64(0.44698684219414125), np.float64(0.4469577851839874), np.float64(0.44665030079480944), np.float64(0.44638977906840094), np.float64(0.44617483613065023), np.float64(0.44601861057403264), np.float64(0.44586128922729434), np.float64(0.4457122101027811), np.float64(0.4455115014223515), np.float64(0.4450946995290321), np.float64(0.445063711147177), np.float64(0.4446322927000511), np.float64(0.444475578433236), np.float64(0.44436181452019863), np.float64(0.4443067293410708), np.float64(0.4442306134772438), np.float64(0.44419157131696274), np.float64(0.44409359426283423), np.float64(0.4438407887539598), np.float64(0.4435252152524063), np.float64(0.44338077373038703), np.float64(0.44333813243816833), np.float64(0.44307227440598523), np.float64(0.4421837205347938), np.float64(0.44215166617461854), np.float64(0.4420369512513443), np.float64(0.441651952997667), np.float64(0.4416322790351691), np.float64(0.44144586974590183), np.float64(0.4414415014896022), np.float64(0.44129721765109436), np.float64(0.4408365158174456), np.float64(0.4405080358673884), np.float64(0.4404373775330566), np.float64(0.43984599403233243), np.float64(0.43969831878240373), np.float64(0.4395254822770363), np.float64(0.43945811457817824), np.float64(0.43943244548036875), np.float64(0.43934918328500405), np.float64(0.4393201344496035), np.float64(0.4391500009948174), np.float64(0.43908938624965776), np.float64(0.43886084257802793), np.float64(0.4387594932852592), np.float64(0.43847819265998345), np.float64(0.4383715481288068), np.float64(0.4383057124947131), np.float64(0.43802094226047916), np.float64(0.4378597974137165), np.float64(0.4378012801104209), np.float64(0.43767605353047123), np.float64(0.43756721894858175), np.float64(0.4373155123058924), np.float64(0.43701932288273154), np.float64(0.43653415324052), np.float64(0.4360776109115057), np.float64(0.43591634276626795), np.float64(0.43574153033624763), np.float64(0.4357242637024491), np.float64(0.4354050609173812), np.float64(0.4353784797006625), np.float64(0.4350694120726702), np.float64(0.4350187108239821), np.float64(0.4347996255494164), np.float64(0.4347293472880271), np.float64(0.43426089096038967), np.float64(0.43416075998166004), np.float64(0.4340419066064642), np.float64(0.433878105336916), np.float64(0.43386693462918646), np.float64(0.4338351014602231), np.float64(0.4338202339367103), np.float64(0.43364545533580806), np.float64(0.4330251412428705), np.float64(0.432634782071641), np.float64(0.43252195379364844), np.float64(0.4322999308984143), np.float64(0.432077794379678), np.float64(0.43182481935757505), np.float64(0.43165799476237665), np.float64(0.431588520597372), np.float64(0.43104335061769805), np.float64(0.43101531021424705), np.float64(0.4309602746130838), np.float64(0.4308293674498025), np.float64(0.4303899093551638), np.float64(0.430277036259547), np.float64(0.43026706978269774), np.float64(0.4296519288679647), np.float64(0.42963712069319077), np.float64(0.4296185037413383), np.float64(0.42950776569866267), np.float64(0.42932092146915535), np.float64(0.42812867907969127), np.float64(0.4275544649575049), np.float64(0.42703561182117006), np.float64(0.4265136841593222), np.float64(0.42634774709639756), np.float64(0.42629541469024923), np.float64(0.4262148731516617), np.float64(0.4261534107878276), np.float64(0.42615001283237525), np.float64(0.42601379564475705), np.float64(0.4257947447574776), np.float64(0.4256830002633333), np.float64(0.4254051035972028), np.float64(0.42534887800707805), np.float64(0.42482994550023956), np.float64(0.4247984273602238), np.float64(0.42464472117042384), np.float64(0.42454811169098283), np.float64(0.42445485020193374), np.float64(0.4242275538886328), np.float64(0.4240209164598263), np.float64(0.4236926832687385), np.float64(0.4234938143879746), np.float64(0.42291062122118167), np.float64(0.42290321346440274), np.float64(0.42266634640799844), np.float64(0.4223583018106075), np.float64(0.42224311860417973), np.float64(0.4218412098705682), np.float64(0.4217250204102806), np.float64(0.42150184486378633), np.float64(0.42112151007290444), np.float64(0.42094664553679484), np.float64(0.4207019736584197), np.float64(0.4205416775453517), np.float64(0.42046992692894786), np.float64(0.4203558173635684), np.float64(0.42012813699660656), np.float64(0.4199858847361312), np.float64(0.4198790314673963), np.float64(0.4198336791729137), np.float64(0.41981970066720453), np.float64(0.4197869170926904), np.float64(0.4197129614182261), np.float64(0.4196941187889242), np.float64(0.4196384796940054), np.float64(0.41963477593061355), np.float64(0.41960196247508147), np.float64(0.4194478023408112), np.float64(0.41935097325144355), np.float64(0.4190933357701243), np.float64(0.4190906705190927), np.float64(0.41908969141409397), np.float64(0.4189133537136737), np.float64(0.41889919687011606), np.float64(0.41872056124111195), np.float64(0.41811314806152955), np.float64(0.4180212646464431), np.float64(0.41758107720727994), np.float64(0.4174595712653096), np.float64(0.41730699514611785), np.float64(0.416990083194161), np.float64(0.4169372389810176), np.float64(0.41667528339576587), np.float64(0.41579762941815157), np.float64(0.4157914606262087), np.float64(0.4148915080317491), np.float64(0.41487752176735726), np.float64(0.41471567784255225), np.float64(0.41460181206574026), np.float64(0.41425655576015125), np.float64(0.414115405152517), np.float64(0.4137687442534693), np.float64(0.41354542749809625), np.float64(0.41345883345539647), np.float64(0.4133401609167529), np.float64(0.41283953361564446), np.float64(0.41242467174599706), np.float64(0.41241362876502796), np.float64(0.4119204995806598), np.float64(0.4115596027736214), np.float64(0.4114198352815428), np.float64(0.41091282017241637), np.float64(0.41078871910062376), np.float64(0.41068162784485546), np.float64(0.41058556969065607), np.float64(0.41038702721444703), np.float64(0.41032552533594313), np.float64(0.41032095059947893), np.float64(0.40992009858908546), np.float64(0.4099064601849236), np.float64(0.40978660217875035), np.float64(0.40963500168337597), np.float64(0.4096181758750547), np.float64(0.4092529160486579), np.float64(0.4092151356874853), np.float64(0.4088881911251362), np.float64(0.40873287838075834), np.float64(0.40861751958753534), np.float64(0.40826149947238977), np.float64(0.4081407682988019), np.float64(0.40812980885378264), np.float64(0.4079315833416069), np.float64(0.4074939859349785), np.float64(0.4068569078561008), np.float64(0.40673240329172233), np.float64(0.4067013232254937), np.float64(0.40645919991777735), np.float64(0.4063077063671076), np.float64(0.4062747567097174), np.float64(0.4061696395358084), np.float64(0.4061651620742469), np.float64(0.40580356977999277), np.float64(0.40568126971967566), np.float64(0.4053096791662811), np.float64(0.40518333348374685), np.float64(0.4051128543348931), np.float64(0.4049198536454291), np.float64(0.40490123451173304), np.float64(0.4048348028690303), np.float64(0.4047480735823937), np.float64(0.4041594695118853), np.float64(0.4039182262081675), np.float64(0.4034065662981437), np.float64(0.4031395300652567), np.float64(0.40304620327964336), np.float64(0.40303277112937363), np.float64(0.4029609146392737), np.float64(0.40290234762737914), np.float64(0.40277677449181376), np.float64(0.40273939128656927), np.float64(0.40248553694042366), np.float64(0.4024523535638594), np.float64(0.40215501022861205), np.float64(0.4020678901693774), np.float64(0.40205985677754424), np.float64(0.40202933273701336), np.float64(0.4019788259128936), np.float64(0.4017574884969371), np.float64(0.401706225574019), np.float64(0.40161060484629485), np.float64(0.401547968254332), np.float64(0.4014636010396442), np.float64(0.40142599068291224), np.float64(0.40138674763618637), np.float64(0.4008453506264509), np.float64(0.40064285259726096), np.float64(0.40053386630223564), np.float64(0.40010504213580383), np.float64(0.399651318905459), np.float64(0.3995583067862984), np.float64(0.39951408143594835), np.float64(0.399185120873859), np.float64(0.39918095299206596), np.float64(0.3990628837325411), np.float64(0.39881655308524494), np.float64(0.39880384966418786), np.float64(0.3983478499312309), np.float64(0.39825369459800897), np.float64(0.3981648069696996), np.float64(0.3979001260769482), np.float64(0.397694847985727), np.float64(0.39761791498340193), np.float64(0.3975832365225655), np.float64(0.39746796315156185), np.float64(0.3973266559171921), np.float64(0.3972951459515627), np.float64(0.3972117191826234), np.float64(0.39709896150329815), np.float64(0.39706353675910677), np.float64(0.39693116290596775), np.float64(0.3968324802052394), np.float64(0.3965478193137363), np.float64(0.39654760722724863), np.float64(0.3963290587124681), np.float64(0.3959358266433036), np.float64(0.3958653459862498), np.float64(0.3957771843092974), np.float64(0.3956879955531095), np.float64(0.39545691355645224), np.float64(0.3954545046302301), np.float64(0.3954239470714267), np.float64(0.39529305592756675), np.float64(0.3952401674170433), np.float64(0.3952271937948565), np.float64(0.3951873009456184), np.float64(0.3951054350051683), np.float64(0.3950135737601275), np.float64(0.39491011394013154), np.float64(0.39482082590963147), np.float64(0.3946921400585033), np.float64(0.3944995162639814), np.float64(0.39447334344924395), np.float64(0.39446440046915304), np.float64(0.3943052418238302), np.float64(0.3940459589934411), np.float64(0.3939506015766212), np.float64(0.393918547626864), np.float64(0.3937037201150913), np.float64(0.39365495079743223), np.float64(0.39355283214594855), np.float64(0.3934514607555205), np.float64(0.3931224180855921), np.float64(0.3930990678258674), np.float64(0.39302232263608766), np.float64(0.39244280655792146), np.float64(0.39228601586257733), np.float64(0.3921851687022847), np.float64(0.39176955103468925), np.float64(0.3915668769014837), np.float64(0.39149764239242957), np.float64(0.3912089897513681), np.float64(0.391090476539471), np.float64(0.3909886894055472), np.float64(0.3909238177114804), np.float64(0.3908403298278617), np.float64(0.39072834345686797), np.float64(0.39029383230852704), np.float64(0.3902704707260948), np.float64(0.3901259678908833), np.float64(0.3900946141861156), np.float64(0.390048432105815), np.float64(0.39001667578341903), np.float64(0.3899704312771763), np.float64(0.38988917833225384), np.float64(0.389664500554031), np.float64(0.38964367458933485), np.float64(0.3895717333674892), np.float64(0.389526046019402), np.float64(0.38950062826309045), np.float64(0.38936570684933364), np.float64(0.3892844697933218), np.float64(0.3892278387103156), np.float64(0.3889975297816269), np.float64(0.3889903321462974), np.float64(0.38878169565812454), np.float64(0.3887225796203675), np.float64(0.3885797303164874), np.float64(0.3879649741670747), np.float64(0.3876790384973043), np.float64(0.38761518268945866), np.float64(0.3874076539911604), np.float64(0.38722596313597074), np.float64(0.38720365382466426), np.float64(0.38694501742482834), np.float64(0.3869287904216435), np.float64(0.386672459813971), np.float64(0.3866345789549946), np.float64(0.386520775873375), np.float64(0.38649288776233526), np.float64(0.3858339713480134), np.float64(0.38579439354423467), np.float64(0.3857432661769658), np.float64(0.3855326381878588), np.float64(0.38548034040396756), np.float64(0.38539506196794376), np.float64(0.3853186866915376), np.float64(0.3852405013624515), np.float64(0.38514425295937627), np.float64(0.3847887868476553), np.float64(0.38478718181983196), np.float64(0.3847255998149608), np.float64(0.38439328008453105), np.float64(0.38420972738140413), np.float64(0.3840273875608447), np.float64(0.3838863849154655), np.float64(0.38387713377966), np.float64(0.38362769340238156), np.float64(0.38346872655352693), np.float64(0.383397505808569), np.float64(0.3833822681964162), np.float64(0.3833453646510298), np.float64(0.3828815400201918), np.float64(0.38247597130849337), np.float64(0.3823522910230856), np.float64(0.3822512932226204), np.float64(0.3821685756878685), np.float64(0.38192012411093434), np.float64(0.38179560924091943), np.float64(0.3813687079642187), np.float64(0.38123688207236034), np.float64(0.38105087889223915), np.float64(0.3802393538107885), np.float64(0.38011392789427767), np.float64(0.379983984150286), np.float64(0.37986589819969463), np.float64(0.3797391331570765), np.float64(0.37972426754152333), np.float64(0.37966179919483606), np.float64(0.37960263081427514), np.float64(0.37954221158990464), np.float64(0.3792846480727374), np.float64(0.3792220690163841), np.float64(0.3790243706079901), np.float64(0.37901558157052717), np.float64(0.378955166518989), np.float64(0.3785508851816375), np.float64(0.37849729530812437), np.float64(0.3784140340820555), np.float64(0.37835248227670226), np.float64(0.3782412814604433), np.float64(0.3781400952725044), np.float64(0.37803339039184825), np.float64(0.3778895406017116), np.float64(0.3778457777491528), np.float64(0.37758200564155986), np.float64(0.37753144462523164), np.float64(0.3774174091591186), np.float64(0.3771797598764174), np.float64(0.37705353042154305), np.float64(0.37705008772031207), np.float64(0.3769287348110902), np.float64(0.3768966811696466), np.float64(0.37674808196593573), np.float64(0.3766458155815158), np.float64(0.3764481057688523), np.float64(0.37632519555808414), np.float64(0.37627043894420514), np.float64(0.3760272486922943), np.float64(0.37594537626694635), np.float64(0.3758108474734823), np.float64(0.3757866582756472), np.float64(0.37547016336466454), np.float64(0.37536527955232607), np.float64(0.3752449506554855), np.float64(0.3751968910640843), np.float64(0.3744683678020706), np.float64(0.37413429715441837), np.float64(0.3740501962758293), np.float64(0.3735576256012079), np.float64(0.3734817336362182), np.float64(0.37345745769814964), np.float64(0.3734167216942896), np.float64(0.37321136893559964), np.float64(0.3727440749885083), np.float64(0.37269929348625647), np.float64(0.37263323668407144), np.float64(0.372312852857213), np.float64(0.3722451477950206), np.float64(0.37223467680313466), np.float64(0.3719957517523208), np.float64(0.3719598938927173), np.float64(0.3717490161646419), np.float64(0.37160872829146124), np.float64(0.37149213286871724), np.float64(0.3714827989532719), np.float64(0.37142060197093213), np.float64(0.37130536596803737), np.float64(0.3712523152013296), np.float64(0.37119794721498794), np.float64(0.37113660748201666), np.float64(0.37090391919343507), np.float64(0.37087040335236404), np.float64(0.3707670781298276), np.float64(0.3705779416935244), np.float64(0.3705758131209318), np.float64(0.3703650107137372), np.float64(0.37033358631998536), np.float64(0.3703116469360035), np.float64(0.3699232302518005), np.float64(0.36991193045751664), np.float64(0.36982967400240263), np.float64(0.36970424248723355), np.float64(0.3696377744700956), np.float64(0.3692135783711469), np.float64(0.3692114964771619), np.float64(0.3691833663064727), np.float64(0.36901888607411915), np.float64(0.36898764985163224), np.float64(0.36895354420662624), np.float64(0.3689520811540461), np.float64(0.3686302161024777), np.float64(0.368542782678587), np.float64(0.36853258183920296), np.float64(0.3684885779713431), np.float64(0.36846782575955106), np.float64(0.3684669196748749), np.float64(0.36802769126892426), np.float64(0.3680069976816904), np.float64(0.36798234849480316), np.float64(0.3675366458499806), np.float64(0.3674604447855838), np.float64(0.3674316787218817), np.float64(0.3673638515367607), np.float64(0.3670205622062374), np.float64(0.36700776776826266), np.float64(0.3668774355034968), np.float64(0.3668638356044894), np.float64(0.3664110053523525), np.float64(0.3663624727984381), np.float64(0.36630543999173826), np.float64(0.3660518351552831), np.float64(0.36598055563819093), np.float64(0.3658643885123296), np.float64(0.3658415012659603), np.float64(0.36561866104178853), np.float64(0.3653516792046602), np.float64(0.3652136633814544), np.float64(0.36479883791833384), np.float64(0.36478284312819126), np.float64(0.3647677587676518), np.float64(0.36447993174677856), np.float64(0.3644644745446146), np.float64(0.36417472197492007), np.float64(0.3639929829897104), np.float64(0.3637210702579344), np.float64(0.3637104677571038), np.float64(0.36360250235519137), np.float64(0.3634569538783192), np.float64(0.36320652212755167), np.float64(0.3630891874819059), np.float64(0.3629495816730245), np.float64(0.3629475352052984), np.float64(0.36261291626072045), np.float64(0.3626009669701654), np.float64(0.36237138177532907), np.float64(0.3623443123004943), np.float64(0.36233096812862675), np.float64(0.3623109340262813), np.float64(0.36221878949283404), np.float64(0.3622118835272685), np.float64(0.36215103786729186), np.float64(0.3614927847596415), np.float64(0.3613700911648619), np.float64(0.36107475172210873), np.float64(0.36077581921573776), np.float64(0.3607246601771406), np.float64(0.36032841735647886), np.float64(0.36029181608644717), np.float64(0.3602583923941351), np.float64(0.3600768484057692), np.float64(0.36007641516288913), np.float64(0.35990520615290866), np.float64(0.3597627802701638), np.float64(0.35975061496679295), np.float64(0.35964991167041355), np.float64(0.3593823928147634), np.float64(0.3593571100892292), np.float64(0.3592400790874467), np.float64(0.3592193802396074), np.float64(0.35921548126148906), np.float64(0.3591684239123854), np.float64(0.3590168774991797), np.float64(0.3589582435673991), np.float64(0.358922157320718), np.float64(0.3587648813843592), np.float64(0.3587242343219427), np.float64(0.3586825036200179), np.float64(0.3586377267496335), np.float64(0.35860188641321356), np.float64(0.35855158922535424), np.float64(0.3580430322556867), np.float64(0.3580243935808402), np.float64(0.35802269897422295), np.float64(0.35799533044997334), np.float64(0.35787433837304283), np.float64(0.3577275630983379), np.float64(0.35749571372988237), np.float64(0.35749350807256963), np.float64(0.3573317934837214), np.float64(0.3571024624248753), np.float64(0.35709026516442394), np.float64(0.3569438153594211), np.float64(0.35693740490411446), np.float64(0.3568150560641507), np.float64(0.3566734757547164), np.float64(0.35655257880211666), np.float64(0.3565339985333729), np.float64(0.3562495922856398), np.float64(0.35589615510588457), np.float64(0.3558159951826331), np.float64(0.3556302740134594), np.float64(0.35562104922068694), np.float64(0.3554048538770597), np.float64(0.3553554524447209), np.float64(0.35521803855250556), np.float64(0.3552152534656569), np.float64(0.3550400920908672), np.float64(0.3546744872939787), np.float64(0.3546332188753318), np.float64(0.35458727933630163), np.float64(0.35458407818810833), np.float64(0.3545554644361255), np.float64(0.3542406513748091), np.float64(0.35408801747734453), np.float64(0.3535777401751425), np.float64(0.35345106972471235), np.float64(0.35333095330548014), np.float64(0.35325849970842166), np.float64(0.35325163380192864), np.float64(0.3531919245403767), np.float64(0.3531075903983336), np.float64(0.35310210588364793), np.float64(0.3530025590465977), np.float64(0.3529806700265814), np.float64(0.3529211864789257), np.float64(0.35275671625007543), np.float64(0.352683656087821), np.float64(0.3525781717282596), np.float64(0.3525764897664877), np.float64(0.3524895689969037), np.float64(0.3524588965740082), np.float64(0.35238617341875744), np.float64(0.35236762276208167), np.float64(0.35236559492839237), np.float64(0.3521484486016475), np.float64(0.3521474926905749), np.float64(0.35195476931066744), np.float64(0.3519486636230404), np.float64(0.3518343978055066), np.float64(0.35055952084889), np.float64(0.3502311407967702), np.float64(0.34995616556042497), np.float64(0.34989847354789), np.float64(0.3498580081381553), np.float64(0.3496806077283142), np.float64(0.3496182925143497), np.float64(0.34936364411326903), np.float64(0.34929344210829555), np.float64(0.3491914350385823), np.float64(0.34908646606695315), np.float64(0.3489245589524733), np.float64(0.3488937161884853), np.float64(0.34881839232485934), np.float64(0.34877203663670797), np.float64(0.3486169355120319), np.float64(0.34853372497199203), np.float64(0.34812033401084336), np.float64(0.3479480117297832), np.float64(0.3478050127885069), np.float64(0.3477951650999903), np.float64(0.34771687947606084), np.float64(0.34753469544530957), np.float64(0.34746076345503063), np.float64(0.34739323689678814), np.float64(0.34710281158150313), np.float64(0.3470071481213867), np.float64(0.3467697475591321), np.float64(0.34662592599257974), np.float64(0.3465841319608884), np.float64(0.3464852515475826), np.float64(0.34647610988845146), np.float64(0.3462962339952012), np.float64(0.34620032191299843), np.float64(0.3461325976459437), np.float64(0.3460533680181716), np.float64(0.34588942689137103), np.float64(0.34577431351117743), np.float64(0.345717293196767), np.float64(0.34564427784011276), np.float64(0.34539180740522585), np.float64(0.3453718732616083), np.float64(0.3448191978167241), np.float64(0.34478743983150456), np.float64(0.3446493856707616), np.float64(0.34451233887050453), np.float64(0.3442514562091567), np.float64(0.3441124033812051), np.float64(0.3441100874451175), np.float64(0.3440275670033371), np.float64(0.34398080337073433), np.float64(0.3438816673214729), np.float64(0.34386979459697425), np.float64(0.34367666303450106), np.float64(0.34363052837321423), np.float64(0.3436253384333079), np.float64(0.3435927629921397), np.float64(0.3434601508043794), np.float64(0.3434056875563056), np.float64(0.3430649230038183), np.float64(0.3429221066209464), np.float64(0.34281558540209595), np.float64(0.34256702817619694), np.float64(0.3423973624460444), np.float64(0.34235878829334787), np.float64(0.3423105450328996), np.float64(0.3422478137201494), np.float64(0.34213808943125945), np.float64(0.34211512708268266), np.float64(0.34198830554384607), np.float64(0.3419151198458779), np.float64(0.34189038288512846), np.float64(0.3415312910672688), np.float64(0.34144048483808975), np.float64(0.34122495756559723), np.float64(0.3411976919097741), np.float64(0.3410951956137428), np.float64(0.3409776537755674), np.float64(0.34076178025147424), np.float64(0.3407576046928627), np.float64(0.3405981344396327), np.float64(0.34045377114253833), np.float64(0.3404408531642204), np.float64(0.3402568920776838), np.float64(0.33986732414628357), np.float64(0.3397781663380976), np.float64(0.33971077616311857), np.float64(0.3395170003445233), np.float64(0.33929595843661553), np.float64(0.33920685089103025), np.float64(0.3391421967674074), np.float64(0.3389774401321676), np.float64(0.3388023060312617), np.float64(0.3387124773091206), np.float64(0.33858613291452083), np.float64(0.338496691186101), np.float64(0.3382256516094044), np.float64(0.3380421382915694), np.float64(0.33791660452412925), np.float64(0.3379038451779843), np.float64(0.3375378606672748), np.float64(0.3375305997801791), np.float64(0.3375245021204243), np.float64(0.3373520011329666), np.float64(0.33731225008866605), np.float64(0.337081639037265), np.float64(0.33707436133198865), np.float64(0.3370707788612406), np.float64(0.33697621448005805), np.float64(0.33695350527077783), np.float64(0.33670373702354633), np.float64(0.33663040392272997), np.float64(0.33608554752442454), np.float64(0.33598792209842715), np.float64(0.335968870046079), np.float64(0.3358064140838388), np.float64(0.3356940832567924), np.float64(0.3356592574140889), np.float64(0.335603662586531), np.float64(0.3354194794440587), np.float64(0.33541782787621194), np.float64(0.33523404407223567), np.float64(0.3350181423794615), np.float64(0.3347172432194407), np.float64(0.33469407217275665), np.float64(0.33459585804002584), np.float64(0.3345850255596535), np.float64(0.33456716361662914), np.float64(0.334490120265448), np.float64(0.3343663733651298), np.float64(0.33415646319519793), np.float64(0.33402171258367674), np.float64(0.3338345070181204), np.float64(0.33377561288619734), np.float64(0.3337435932739642), np.float64(0.33305770812366436), np.float64(0.3326737583953943), np.float64(0.33260238849943713), np.float64(0.3324504738667825), np.float64(0.33243592030516805), np.float64(0.33243417823137233), np.float64(0.33239393428740377), np.float64(0.3323748438981099), np.float64(0.33189278838851416), np.float64(0.3317882110911719), np.float64(0.33176732453083935), np.float64(0.3317362970843949), np.float64(0.33170666248300046), np.float64(0.3315594679093155), np.float64(0.3315541086398967), np.float64(0.3315006834796884), np.float64(0.33147812295184337), np.float64(0.33144925315818546), np.float64(0.33111509730949595), np.float64(0.33101497162650206), np.float64(0.3306097240501115), np.float64(0.3304803296667056), np.float64(0.3304802793970567), np.float64(0.3303350497824716), np.float64(0.33024363371708976), np.float64(0.3301925586096225), np.float64(0.3301882853156897), np.float64(0.3301657171168144), np.float64(0.3297250488362222), np.float64(0.3293448301027448), np.float64(0.3281723732869659), np.float64(0.3280931793139503), np.float64(0.3277423502289016), np.float64(0.3276477800987683), np.float64(0.3276462055114493), np.float64(0.3276045075345168), np.float64(0.32747673041291414), np.float64(0.3274054998543754), np.float64(0.32736272690728935), np.float64(0.3272005173182297), np.float64(0.3271316610243974), np.float64(0.32703216740773533), np.float64(0.32669781029479816), np.float64(0.32623659525238047), np.float64(0.3261707000934871), np.float64(0.32579958776993334), np.float64(0.32545999720685065), np.float64(0.32534104184886076), np.float64(0.3251317369919815), np.float64(0.3249939474936543), np.float64(0.32490652501893924), np.float64(0.32465006077844466), np.float64(0.3240862073808329), np.float64(0.32398835542648446), np.float64(0.3236412444432867), np.float64(0.3236312715968614), np.float64(0.32348854044977027), np.float64(0.323367514549963), np.float64(0.32326982980890206), np.float64(0.3230734187529302), np.float64(0.3230559597120741), np.float64(0.3230441447114462), np.float64(0.3228359577751449), np.float64(0.3223092911938028), np.float64(0.32216357088188635), np.float64(0.322145298810457), np.float64(0.3221180539010277), np.float64(0.3217400302804307), np.float64(0.32148738338436056), np.float64(0.32142950604870824), np.float64(0.3211318515537617), np.float64(0.3200223079017963), np.float64(0.3199508265902816), np.float64(0.3197729596713351), np.float64(0.319650935345638), np.float64(0.3196376547468712), np.float64(0.31950201724849064), np.float64(0.3192876980814347), np.float64(0.31918903386265307), np.float64(0.3188630679129869), np.float64(0.31860577057415346), np.float64(0.3177221968448009), np.float64(0.31761786702218225), np.float64(0.3173171435024618), np.float64(0.3172424762165787), np.float64(0.317163776575104), np.float64(0.316719367759705), np.float64(0.3164129751977526), np.float64(0.31551859270835203), np.float64(0.315100440084984), np.float64(0.3149042378944458), np.float64(0.3148582504207036), np.float64(0.31424350417964536), np.float64(0.31418457577925774), np.float64(0.3137564302723231), np.float64(0.313746981803553), np.float64(0.3134213448354442), np.float64(0.31304192880806875), np.float64(0.31302876530593127), np.float64(0.3128752294787151), np.float64(0.31277511894701776), np.float64(0.31267163041251755), np.float64(0.3125504052369943), np.float64(0.3123487596929138), np.float64(0.31227694453314614), np.float64(0.31226516861675585), np.float64(0.3122607078835014), np.float64(0.31196931656638316), np.float64(0.31193754257066003), np.float64(0.3118740878010244), np.float64(0.3117531716096158), np.float64(0.31170768317091346), np.float64(0.3116587273929034), np.float64(0.31160149309381), np.float64(0.31131970643817003), np.float64(0.31105584105737555), np.float64(0.3110325440977554), np.float64(0.3110064498464491), np.float64(0.31054034600267), np.float64(0.3102745666967265), np.float64(0.3099129770344939), np.float64(0.3093106950294701), np.float64(0.309003821281114), np.float64(0.308838372680544), np.float64(0.30857440040474005), np.float64(0.3083012059040829), np.float64(0.3082426353584987), np.float64(0.30801248237601203), np.float64(0.30783859020927157), np.float64(0.3077483515164317), np.float64(0.30764578798040937), np.float64(0.3070877897489396), np.float64(0.3070071729320312), np.float64(0.30675088326519784), np.float64(0.3065099351673891), np.float64(0.3060441379234656), np.float64(0.3059572234965181), np.float64(0.30573997441307293), np.float64(0.3051650026629847), np.float64(0.3050864412389585), np.float64(0.3046027632333789), np.float64(0.3045760513786903), np.float64(0.3038232785821759), np.float64(0.3038201836781704), np.float64(0.303356932869947), np.float64(0.30308646757184626), np.float64(0.3024972541819574), np.float64(0.30245802321105225), np.float64(0.3023906758948532), np.float64(0.3017722576696188), np.float64(0.301271847794959), np.float64(0.3011996341652464), np.float64(0.3009781849227094), np.float64(0.30097767368615663), np.float64(0.3006612497724747), np.float64(0.3002405570818797), np.float64(0.30023612375713143), np.float64(0.3001542205328212), np.float64(0.29992772380349636), np.float64(0.2996846482723623), np.float64(0.2996460386915999), np.float64(0.29904356798161674), np.float64(0.29882646314508743), np.float64(0.29879394995227376), np.float64(0.2981077849202402), np.float64(0.29780624902274055), np.float64(0.29759325036601136), np.float64(0.2974888754645615), np.float64(0.29715211875994063), np.float64(0.29682463770531503), np.float64(0.29609364985311015), np.float64(0.29578033405999715), np.float64(0.2953960006479624), np.float64(0.2953583979723323), np.float64(0.2951535542850045), np.float64(0.2950876544091983), np.float64(0.2948811317622475), np.float64(0.29486796561234396), np.float64(0.2947554859645952), np.float64(0.29433053019149724), np.float64(0.29423754183522727), np.float64(0.2939762884557695), np.float64(0.29384989089187896), np.float64(0.29376133130694126), np.float64(0.29374585455659746), np.float64(0.2932370305584481), np.float64(0.2932013083958577), np.float64(0.29254201958519804), np.float64(0.29224912556475346), np.float64(0.2920229780707332), np.float64(0.2919944952003669), np.float64(0.2918368267651621), np.float64(0.2916978731745073), np.float64(0.2910187543713468), np.float64(0.2907163097918564), np.float64(0.2905110294503541), np.float64(0.2900093468511137), np.float64(0.289991565347342), np.float64(0.2897930135173634), np.float64(0.28975685626781195), np.float64(0.28971112920378), np.float64(0.289704452960776), np.float64(0.289061748164153), np.float64(0.2889570082409788), np.float64(0.28818299634011374), np.float64(0.2871971876097174), np.float64(0.2871663027159949), np.float64(0.28669702441113953), np.float64(0.28655284657755337), np.float64(0.28605355359972057), np.float64(0.28592595179430896), np.float64(0.2858016388720283), np.float64(0.28573318323264946), np.float64(0.28541759089873375), np.float64(0.2852979874793063), np.float64(0.2850498706162486), np.float64(0.2850383404067673), np.float64(0.2847300817120756), np.float64(0.2845407218645818), np.float64(0.2840603459151585), np.float64(0.28402131425520777), np.float64(0.2825528003986589), np.float64(0.2824589475320565), np.float64(0.281951418509336), np.float64(0.2817466535570926), np.float64(0.2816015974673779), np.float64(0.28141543820567017), np.float64(0.2813862962892067), np.float64(0.28089280469963696), np.float64(0.28087103676507263), np.float64(0.2807467634835461), np.float64(0.27962948820204325), np.float64(0.27906406289871993), np.float64(0.27894721147165996), np.float64(0.2787866752576524), np.float64(0.2786087931262839), np.float64(0.2785947756526606), np.float64(0.27630150808064735), np.float64(0.27580474669195887), np.float64(0.27575879903953693), np.float64(0.2751855500527744), np.float64(0.27442732079548793), np.float64(0.2720120050283515), np.float64(0.2705633518747535), np.float64(0.2694344793300252), np.float64(0.2691003472326804), np.float64(0.26909484335774525), np.float64(0.2688885828115496), np.float64(0.26843976726744573), np.float64(0.2673728736646188), np.float64(0.2668209370939296), np.float64(0.26559832707291187), np.float64(0.2650562128913436), np.float64(0.26410444303720815), np.float64(0.2631729732694812), np.float64(0.2606401908514464), np.float64(0.26042960180052216), np.float64(0.2600898593290364), np.float64(0.2587477496129803), np.float64(0.2585502545455789), np.float64(0.2585465894666273), np.float64(0.2578839751254635), np.float64(0.2575509710528643), np.float64(0.2574199100164175), np.float64(0.25195847521615583), np.float64(0.24471945410896295), np.float64(0.23763827694942385), np.float64(0.23664375932806136), np.float64(0.2357872013848041), np.float64(0.225020221294495)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(density_matrix[130], reverse = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31809d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pais: United Rep. of Tanzania \n",
      "\n",
      "0102\n",
      "3     Bovine animals: live, pure-bred breeding animals\n",
      "4    Bovine animals: live, other than pure-bred bre...\n",
      "Name: description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "obtain_product_and_country_from_edge(129,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5daf67",
   "metadata": {},
   "source": [
    "## Usando solo densidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9120c250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.97      0.93     28661\n",
      "         1.0       0.62      0.28      0.39      4713\n",
      "\n",
      "    accuracy                           0.87     33374\n",
      "   macro avg       0.76      0.63      0.66     33374\n",
      "weighted avg       0.85      0.87      0.85     33374\n",
      "\n",
      "Accuracy: 0.8744831305806916\n"
     ]
    }
   ],
   "source": [
    "X = density_matrix.flatten().reshape(-1, 1) # input: densidad\n",
    "y = adj_matrices[22].flatten() # output: rca binario (0 o 1)\n",
    "\n",
    "\n",
    "#train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#training\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#PredicciÃ³n\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#Metricas\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7769daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.79      0.86     28661\n",
      "         1.0       0.36      0.70      0.47      4713\n",
      "\n",
      "    accuracy                           0.78     33374\n",
      "   macro avg       0.65      0.74      0.67     33374\n",
      "weighted avg       0.86      0.78      0.81     33374\n",
      "\n",
      "Accuracy: 0.7790195960927668\n"
     ]
    }
   ],
   "source": [
    "#train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#training\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#PredicciÃ³n\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#Metricas\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937f2f11",
   "metadata": {},
   "source": [
    "## Usando RCA y densidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb84b8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.99      0.96     28661\n",
      "         1.0       0.93      0.59      0.72      4713\n",
      "\n",
      "    accuracy                           0.94     33374\n",
      "   macro avg       0.93      0.79      0.84     33374\n",
      "weighted avg       0.94      0.94      0.93     33374\n",
      "\n",
      "Accuracy: 0.935758374782765\n"
     ]
    }
   ],
   "source": [
    "X = adj_matrices_nb[21].flatten().reshape(-1, 1) # input: RCA no binario\n",
    "y = adj_matrices[22].flatten() # output: rca binario (0 o 1)\n",
    "\n",
    "\n",
    "#train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#training\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#PredicciÃ³n\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#Metricas\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c91b4803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     28661\n",
      "         1.0       0.93      0.66      0.77      4713\n",
      "\n",
      "    accuracy                           0.94     33374\n",
      "   macro avg       0.94      0.82      0.87     33374\n",
      "weighted avg       0.94      0.94      0.94     33374\n",
      "\n",
      "Accuracy: 0.9444178102714688\n"
     ]
    }
   ],
   "source": [
    "#Densidad como feature\n",
    "densities = density_matrix.flatten().reshape(-1, 1)\n",
    "\n",
    "#RCA continuo como feature\n",
    "rca_values = adj_matrices_nb[21].flatten().reshape(-1, 1) \n",
    "\n",
    "# rca binario\n",
    "y = adj_matrices[22].flatten()  \n",
    "#features: densidad y RCA\n",
    "X = np.hstack([densities, rca_values])  \n",
    "\n",
    "#Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#train\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#PredicciÃ³n\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#MÃ©tricas de clasficiaciÃ³n\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1b12a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.95      0.97     28661\n",
      "         1.0       0.76      0.90      0.82      4713\n",
      "\n",
      "    accuracy                           0.94     33374\n",
      "   macro avg       0.87      0.93      0.89     33374\n",
      "weighted avg       0.95      0.94      0.95     33374\n",
      "\n",
      "Accuracy: 0.9445077006052616\n"
     ]
    }
   ],
   "source": [
    "#Densidad como feature\n",
    "densities = density_matrix.flatten().reshape(-1, 1)\n",
    "\n",
    "#RCA continuo como feature\n",
    "rca_values = adj_matrices_nb[21].flatten().reshape(-1, 1) \n",
    "\n",
    "# rca binario\n",
    "y = adj_matrices[22].flatten()  \n",
    "#features: densidad y RCA\n",
    "X = np.hstack([densities, rca_values])  \n",
    "\n",
    "#Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#train\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#PredicciÃ³n\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#MÃ©tricas de clasficiaciÃ³n\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a73abc",
   "metadata": {},
   "source": [
    "## Predecir multiples aÃ±os hacia adelante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "56dfc7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EvaluaciÃ³n para aÃ±o 22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     28661\n",
      "         1.0       0.93      0.66      0.77      4713\n",
      "\n",
      "    accuracy                           0.94     33374\n",
      "   macro avg       0.94      0.82      0.87     33374\n",
      "weighted avg       0.94      0.94      0.94     33374\n",
      "\n",
      "Accuracy: 0.9444178102714688\n",
      "\n",
      "PredicciÃ³n para snapshot 23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.99      0.97    143410\n",
      "         1.0       0.91      0.65      0.75     23456\n",
      "\n",
      "    accuracy                           0.94    166866\n",
      "   macro avg       0.93      0.82      0.86    166866\n",
      "weighted avg       0.94      0.94      0.94    166866\n",
      "\n",
      "Accuracy: 0.9406649647022162\n",
      "\n",
      "PredicciÃ³n para snapshot 24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.99      0.96    143605\n",
      "         1.0       0.89      0.64      0.74     23261\n",
      "\n",
      "    accuracy                           0.94    166866\n",
      "   macro avg       0.91      0.81      0.85    166866\n",
      "weighted avg       0.94      0.94      0.93    166866\n",
      "\n",
      "Accuracy: 0.9377824122349669\n",
      "\n",
      "PredicciÃ³n para snapshot 25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96    143950\n",
      "         1.0       0.86      0.63      0.73     22916\n",
      "\n",
      "    accuracy                           0.94    166866\n",
      "   macro avg       0.90      0.81      0.85    166866\n",
      "weighted avg       0.93      0.94      0.93    166866\n",
      "\n",
      "Accuracy: 0.9355111286900867\n",
      "\n",
      "PredicciÃ³n para snapshot 26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96    143801\n",
      "         1.0       0.85      0.62      0.72     23065\n",
      "\n",
      "    accuracy                           0.93    166866\n",
      "   macro avg       0.90      0.80      0.84    166866\n",
      "weighted avg       0.93      0.93      0.93    166866\n",
      "\n",
      "Accuracy: 0.9323768772548032\n",
      "\n",
      "PredicciÃ³n para snapshot 27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96    143970\n",
      "         1.0       0.83      0.61      0.70     22896\n",
      "\n",
      "    accuracy                           0.93    166866\n",
      "   macro avg       0.89      0.79      0.83    166866\n",
      "weighted avg       0.93      0.93      0.92    166866\n",
      "\n",
      "Accuracy: 0.9295063104526986\n"
     ]
    }
   ],
   "source": [
    "#Snapshot base (21)\n",
    "t = 21\n",
    "\n",
    "#Features del aÃ±o t\n",
    "densities = density_matrix.flatten().reshape(-1, 1)\n",
    "rca_values = adj_matrices_nb[t].flatten().reshape(-1, 1)\n",
    "X = np.hstack([densities, rca_values])\n",
    "\n",
    "#Target del aÃ±o t+1 para training\n",
    "y = adj_matrices[t + 1].flatten()\n",
    "\n",
    "#Train test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#train\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluo en t+1 como antes\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"\\nEvaluaciÃ³n para aÃ±o {t+1}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "#Sigo evaluando en los siguientes aÃ±os como hacia con ddne y la baseline\n",
    "for year in range(t + 2, 28):  \n",
    "    print(f\"\\nPredicciÃ³n para snapshot {year}\")\n",
    "\n",
    "    #Target real del snapshot futuro\n",
    "    y_future = adj_matrices[year].flatten()\n",
    "\n",
    "    #Seguimos usando los features X del aÃ±o 21\n",
    "    y_pred_future = model.predict(X)\n",
    "\n",
    "    print(classification_report(y_future, y_pred_future))\n",
    "    print(\"Accuracy:\", accuracy_score(y_future, y_pred_future))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "643b9429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EvaluaciÃ³n para aÃ±o 22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.95      0.97     28661\n",
      "         1.0       0.76      0.90      0.82      4713\n",
      "\n",
      "    accuracy                           0.94     33374\n",
      "   macro avg       0.87      0.93      0.89     33374\n",
      "weighted avg       0.95      0.94      0.95     33374\n",
      "\n",
      "Accuracy: 0.9445077006052616\n",
      "\n",
      "PredicciÃ³n para snapshot 23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.95      0.96    143410\n",
      "         1.0       0.72      0.87      0.79     23456\n",
      "\n",
      "    accuracy                           0.94    166866\n",
      "   macro avg       0.85      0.91      0.88    166866\n",
      "weighted avg       0.94      0.94      0.94    166866\n",
      "\n",
      "Accuracy: 0.9353193580477749\n",
      "\n",
      "PredicciÃ³n para snapshot 24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.94      0.96    143605\n",
      "         1.0       0.71      0.86      0.77     23261\n",
      "\n",
      "    accuracy                           0.93    166866\n",
      "   macro avg       0.84      0.90      0.87    166866\n",
      "weighted avg       0.94      0.93      0.93    166866\n",
      "\n",
      "Accuracy: 0.9301355578727841\n",
      "\n",
      "PredicciÃ³n para snapshot 25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.94      0.96    143950\n",
      "         1.0       0.68      0.84      0.75     22916\n",
      "\n",
      "    accuracy                           0.92    166866\n",
      "   macro avg       0.83      0.89      0.86    166866\n",
      "weighted avg       0.93      0.92      0.93    166866\n",
      "\n",
      "Accuracy: 0.92491580070236\n",
      "\n",
      "PredicciÃ³n para snapshot 26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.94      0.95    143801\n",
      "         1.0       0.68      0.83      0.74     23065\n",
      "\n",
      "    accuracy                           0.92    166866\n",
      "   macro avg       0.82      0.88      0.85    166866\n",
      "weighted avg       0.93      0.92      0.92    166866\n",
      "\n",
      "Accuracy: 0.9210624093584073\n",
      "\n",
      "PredicciÃ³n para snapshot 27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95    143970\n",
      "         1.0       0.66      0.81      0.73     22896\n",
      "\n",
      "    accuracy                           0.92    166866\n",
      "   macro avg       0.81      0.87      0.84    166866\n",
      "weighted avg       0.93      0.92      0.92    166866\n",
      "\n",
      "Accuracy: 0.916549806431508\n"
     ]
    }
   ],
   "source": [
    "#Snapshot base (21)\n",
    "t = 21\n",
    "\n",
    "#Features del aÃ±o t\n",
    "densities = density_matrix.flatten().reshape(-1, 1)\n",
    "rca_values = adj_matrices_nb[t].flatten().reshape(-1, 1)\n",
    "X = np.hstack([densities, rca_values])\n",
    "\n",
    "#Target del aÃ±o t+1 para training\n",
    "y = adj_matrices[t + 1].flatten()\n",
    "\n",
    "#Train test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#train\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluo en t+1 como antes\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"\\nEvaluaciÃ³n para aÃ±o {t+1}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "#Sigo evaluando en los siguientes aÃ±os como hacia con ddne y la baseline\n",
    "for year in range(t + 2, 28):  \n",
    "    print(f\"\\nPredicciÃ³n para snapshot {year}\")\n",
    "\n",
    "    #Target real del snapshot futuro\n",
    "    y_future = adj_matrices[year].flatten()\n",
    "\n",
    "    #Seguimos usando los features X del aÃ±o 21\n",
    "    y_pred_future = model.predict(X)\n",
    "\n",
    "    print(classification_report(y_future, y_pred_future))\n",
    "    print(\"Accuracy:\", accuracy_score(y_future, y_pred_future))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01852945",
   "metadata": {},
   "source": [
    "## Regresion sobre el mismo aÃ±o con y sin densidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5333108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EvaluaciÃ³n para snapshot 21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     28730\n",
      "         1.0       1.00      1.00      1.00      4644\n",
      "\n",
      "    accuracy                           1.00     33374\n",
      "   macro avg       1.00      1.00      1.00     33374\n",
      "weighted avg       1.00      1.00      1.00     33374\n",
      "\n",
      "Accuracy: 0.9996704021094265\n",
      "\n",
      "PredicciÃ³n para snapshot 22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.98      0.98    143423\n",
      "         1.0       0.87      0.86      0.87     23443\n",
      "\n",
      "    accuracy                           0.96    166866\n",
      "   macro avg       0.92      0.92      0.92    166866\n",
      "weighted avg       0.96      0.96      0.96    166866\n",
      "\n",
      "Accuracy: 0.9626646530749224\n",
      "\n",
      "PredicciÃ³n para snapshot 23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97    143410\n",
      "         1.0       0.84      0.82      0.83     23456\n",
      "\n",
      "    accuracy                           0.95    166866\n",
      "   macro avg       0.90      0.90      0.90    166866\n",
      "weighted avg       0.95      0.95      0.95    166866\n",
      "\n",
      "Accuracy: 0.9527704864981482\n",
      "\n",
      "PredicciÃ³n para snapshot 24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97    143605\n",
      "         1.0       0.81      0.81      0.81     23261\n",
      "\n",
      "    accuracy                           0.95    166866\n",
      "   macro avg       0.89      0.89      0.89    166866\n",
      "weighted avg       0.95      0.95      0.95    166866\n",
      "\n",
      "Accuracy: 0.9474668296717126\n",
      "\n",
      "PredicciÃ³n para snapshot 25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97    143950\n",
      "         1.0       0.78      0.79      0.79     22916\n",
      "\n",
      "    accuracy                           0.94    166866\n",
      "   macro avg       0.88      0.88      0.88    166866\n",
      "weighted avg       0.94      0.94      0.94    166866\n",
      "\n",
      "Accuracy: 0.9415638895880527\n",
      "\n",
      "PredicciÃ³n para snapshot 26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96    143801\n",
      "         1.0       0.77      0.77      0.77     23065\n",
      "\n",
      "    accuracy                           0.94    166866\n",
      "   macro avg       0.87      0.87      0.87    166866\n",
      "weighted avg       0.94      0.94      0.94    166866\n",
      "\n",
      "Accuracy: 0.9359965481284384\n",
      "\n",
      "PredicciÃ³n para snapshot 27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96    143970\n",
      "         1.0       0.74      0.75      0.75     22896\n",
      "\n",
      "    accuracy                           0.93    166866\n",
      "   macro avg       0.85      0.85      0.85    166866\n",
      "weighted avg       0.93      0.93      0.93    166866\n",
      "\n",
      "Accuracy: 0.9299737513933336\n"
     ]
    }
   ],
   "source": [
    "#Snapshot base (21)\n",
    "t = 21\n",
    "\n",
    "#Features del Snapshot t\n",
    "densities = density_matrix.flatten().reshape(-1, 1)\n",
    "rca_values = adj_matrices_nb[t].flatten().reshape(-1, 1)\n",
    "X = np.hstack([densities, rca_values])\n",
    "\n",
    "#Target del Snapshot t+1 para training\n",
    "y = adj_matrices[t].flatten()\n",
    "\n",
    "#Train test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#train\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluo en t+1 como antes\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"\\nEvaluaciÃ³n para snapshot {t}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "#Sigo evaluando en los siguientes aÃ±os como hacia con ddne y la baseline\n",
    "for year in range(t + 1, 28):  \n",
    "    print(f\"\\nPredicciÃ³n para snapshot {year}\")\n",
    "\n",
    "    #Target real del snapshot futuro\n",
    "    y_future = adj_matrices[year].flatten()\n",
    "\n",
    "    #Seguimos usando los features X del aÃ±o 22\n",
    "    y_pred_future = model.predict(X)\n",
    "\n",
    "    print(classification_report(y_future, y_pred_future))\n",
    "    print(\"Accuracy:\", accuracy_score(y_future, y_pred_future))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "358f8b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EvaluaciÃ³n para snapshot 21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     28730\n",
      "         1.0       1.00      1.00      1.00      4644\n",
      "\n",
      "    accuracy                           1.00     33374\n",
      "   macro avg       1.00      1.00      1.00     33374\n",
      "weighted avg       1.00      1.00      1.00     33374\n",
      "\n",
      "Accuracy: 0.9997003655540241\n",
      "\n",
      "PredicciÃ³n para snapshot 22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.98      0.98    143423\n",
      "         1.0       0.87      0.86      0.87     23443\n",
      "\n",
      "    accuracy                           0.96    166866\n",
      "   macro avg       0.92      0.92      0.92    166866\n",
      "weighted avg       0.96      0.96      0.96    166866\n",
      "\n",
      "Accuracy: 0.9626227032469167\n",
      "\n",
      "PredicciÃ³n para snapshot 23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97    143410\n",
      "         1.0       0.84      0.82      0.83     23456\n",
      "\n",
      "    accuracy                           0.95    166866\n",
      "   macro avg       0.90      0.90      0.90    166866\n",
      "weighted avg       0.95      0.95      0.95    166866\n",
      "\n",
      "Accuracy: 0.9527285366701425\n",
      "\n",
      "PredicciÃ³n para snapshot 24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97    143605\n",
      "         1.0       0.81      0.81      0.81     23261\n",
      "\n",
      "    accuracy                           0.95    166866\n",
      "   macro avg       0.89      0.89      0.89    166866\n",
      "weighted avg       0.95      0.95      0.95    166866\n",
      "\n",
      "Accuracy: 0.9473889228482735\n",
      "\n",
      "PredicciÃ³n para snapshot 25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97    143950\n",
      "         1.0       0.78      0.79      0.79     22916\n",
      "\n",
      "    accuracy                           0.94    166866\n",
      "   macro avg       0.88      0.88      0.88    166866\n",
      "weighted avg       0.94      0.94      0.94    166866\n",
      "\n",
      "Accuracy: 0.9415099540949025\n",
      "\n",
      "PredicciÃ³n para snapshot 26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96    143801\n",
      "         1.0       0.77      0.77      0.77     23065\n",
      "\n",
      "    accuracy                           0.94    166866\n",
      "   macro avg       0.87      0.87      0.87    166866\n",
      "weighted avg       0.94      0.94      0.94    166866\n",
      "\n",
      "Accuracy: 0.9359785696307217\n",
      "\n",
      "PredicciÃ³n para snapshot 27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96    143970\n",
      "         1.0       0.74      0.75      0.75     22896\n",
      "\n",
      "    accuracy                           0.93    166866\n",
      "   macro avg       0.85      0.85      0.85    166866\n",
      "weighted avg       0.93      0.93      0.93    166866\n",
      "\n",
      "Accuracy: 0.9298718732396054\n"
     ]
    }
   ],
   "source": [
    "#Snapshot base (21)\n",
    "t = 21\n",
    "\n",
    "#Features del Snapshot t\n",
    "densities = density_matrix.flatten().reshape(-1, 1)\n",
    "rca_values = adj_matrices_nb[t].flatten().reshape(-1, 1)\n",
    "X = rca_values\n",
    "\n",
    "#Target del Snapshot t+1 para training\n",
    "y = adj_matrices[t].flatten()\n",
    "\n",
    "#Train test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#train\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluo en t+1 como antes\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"\\nEvaluaciÃ³n para snapshot {t}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "#Sigo evaluando en los siguientes aÃ±os como hacia con ddne y la baseline\n",
    "for year in range(t + 1, 28):  \n",
    "    print(f\"\\nPredicciÃ³n para snapshot {year}\")\n",
    "\n",
    "    #Target real del snapshot futuro\n",
    "    y_future = adj_matrices[year].flatten()\n",
    "\n",
    "    #Seguimos usando los features X del aÃ±o 22\n",
    "    y_pred_future = model.predict(X)\n",
    "\n",
    "    print(classification_report(y_future, y_pred_future))\n",
    "    print(\"Accuracy:\", accuracy_score(y_future, y_pred_future))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cc427c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EvaluaciÃ³n para snapshot 21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     28661\n",
      "         1.0       0.93      0.67      0.78      4713\n",
      "\n",
      "    accuracy                           0.95     33374\n",
      "   macro avg       0.94      0.83      0.87     33374\n",
      "weighted avg       0.95      0.95      0.94     33374\n",
      "\n",
      "Accuracy: 0.9463654341703123\n",
      "\n",
      "PredicciÃ³n para snapshot 22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97    143423\n",
      "         1.0       0.93      0.68      0.78     23443\n",
      "\n",
      "    accuracy                           0.95    166866\n",
      "   macro avg       0.94      0.83      0.88    166866\n",
      "weighted avg       0.95      0.95      0.94    166866\n",
      "\n",
      "Accuracy: 0.9475687078254408\n",
      "\n",
      "PredicciÃ³n para snapshot 23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97    143410\n",
      "         1.0       0.90      0.65      0.76     23456\n",
      "\n",
      "    accuracy                           0.94    166866\n",
      "   macro avg       0.92      0.82      0.86    166866\n",
      "weighted avg       0.94      0.94      0.94    166866\n",
      "\n",
      "Accuracy: 0.9411503841405678\n",
      "\n",
      "PredicciÃ³n para snapshot 24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.99      0.96    143605\n",
      "         1.0       0.88      0.64      0.74     23261\n",
      "\n",
      "    accuracy                           0.94    166866\n",
      "   macro avg       0.91      0.81      0.85    166866\n",
      "weighted avg       0.94      0.94      0.93    166866\n",
      "\n",
      "Accuracy: 0.9380161327052845\n",
      "\n",
      "PredicciÃ³n para snapshot 25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96    143950\n",
      "         1.0       0.86      0.64      0.73     22916\n",
      "\n",
      "    accuracy                           0.94    166866\n",
      "   macro avg       0.90      0.81      0.85    166866\n",
      "weighted avg       0.93      0.94      0.93    166866\n",
      "\n",
      "Accuracy: 0.9355650641832368\n",
      "\n",
      "PredicciÃ³n para snapshot 26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96    143801\n",
      "         1.0       0.85      0.62      0.72     23065\n",
      "\n",
      "    accuracy                           0.93    166866\n",
      "   macro avg       0.90      0.80      0.84    166866\n",
      "weighted avg       0.93      0.93      0.93    166866\n",
      "\n",
      "Accuracy: 0.9325626550645428\n",
      "\n",
      "PredicciÃ³n para snapshot 27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96    143970\n",
      "         1.0       0.83      0.61      0.71     22896\n",
      "\n",
      "    accuracy                           0.93    166866\n",
      "   macro avg       0.89      0.80      0.83    166866\n",
      "weighted avg       0.93      0.93      0.93    166866\n",
      "\n",
      "Accuracy: 0.929764002253305\n"
     ]
    }
   ],
   "source": [
    "#Snapshot base (21)\n",
    "t = 21\n",
    "\n",
    "#Features del Snapshot t\n",
    "densities = density_matrix.flatten().reshape(-1, 1)\n",
    "rca_values = adj_matrices_nb[t].flatten().reshape(-1, 1)\n",
    "X = np.hstack([densities, rca_values])\n",
    "\n",
    "#Target del Snapshot t+1 para training\n",
    "y = adj_matrices[t+1].flatten()\n",
    "\n",
    "#Train test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#train\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluo en t+1 como antes\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"\\nEvaluaciÃ³n para snapshot {t+1}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "#Sigo evaluando en los siguientes aÃ±os como hacia con ddne y la baseline\n",
    "for year in range(t + 1, 28):  \n",
    "    print(f\"\\nPredicciÃ³n para snapshot {year}\")\n",
    "\n",
    "    #Target real del snapshot futuro\n",
    "    y_future = adj_matrices[year].flatten()\n",
    "\n",
    "    #Seguimos usando los features X del aÃ±o 22\n",
    "    y_pred_future = model.predict(X)\n",
    "\n",
    "    print(classification_report(y_future, y_pred_future))\n",
    "    print(\"Accuracy:\", accuracy_score(y_future, y_pred_future))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c5efe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
